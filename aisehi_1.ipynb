{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMxipFtdYoLY"
      },
      "source": [
        "#**Compressive Domain Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg3RMzeQYw9h"
      },
      "source": [
        "Carrying necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68PXVDDelqQT"
      },
      "outputs": [],
      "source": [
        "# !pip install torch_xla\n",
        "# Required for tpu processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7frB2b_tejX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.autograd as tag\n",
        "\n",
        "# import torch_xla # for using tpu\n",
        "# import torch_xla.core.xla_model as xm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qGhnOnSZHZM"
      },
      "source": [
        "**DataLoader** and **Download** helper function\n",
        "\n",
        "returns a dictionary of train,test dataloaders with class list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0XtE1CFt-ZK"
      },
      "outputs": [],
      "source": [
        "def get_big_cifar10_data(augmentation=0, root_dir = './data'):\n",
        "  # Data augmentation transformations. Not for Testing!\n",
        "    if augmentation:\n",
        "        transform_train = transforms.Compose([\n",
        "        transforms.Resize(128),\n",
        "        transforms.RandomCrop(128, padding=8, padding_mode='edge'), # Take 128x128 crops from 136x136 padded images\n",
        "        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "    else:\n",
        "        transform_train = transforms.ToTensor()\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(128),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root= root_dir, train=True, download=True,\n",
        "                                            transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True,\n",
        "                                            num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True,\n",
        "                                        transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False,\n",
        "                                            num_workers=2)\n",
        "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    return {'train': trainloader, 'test': testloader, 'classes': classes}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZYOAg7AZpRm"
      },
      "source": [
        "Custom Defined **Quantize Layer** for efficiently transmitting data at lower bit rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5O0RaxTt-VE"
      },
      "outputs": [],
      "source": [
        "class QuantizeFunction(tag.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, tensor, qp=0.5, normalize=True):\n",
        "        ctx.qp = qp\n",
        "        ctx.normalize = normalize\n",
        "        if normalize == True:\n",
        "            output = qp*torch.round(tensor/qp)\n",
        "        else:\n",
        "            output = torch.round(tensor/qp)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        if ctx.normalize == True:\n",
        "            grad_input = grad_output.clone()\n",
        "        else:\n",
        "            grad_input = grad_output.clone()/ctx.qp\n",
        "        return grad_input, None, None\n",
        "\n",
        "class QuantizeLayer(torch.nn.Module):\n",
        "    \"\"\"\n",
        "        Custom defined.\n",
        "    \"\"\"\n",
        "    def __init__(self, qp=0.5, normalize=True):\n",
        "        super(QuantizeLayer, self).__init__()\n",
        "        self.qp = qp\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, input):\n",
        "        return QuantizeFunction.apply(input, self.qp, self.normalize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTl-usi1aZp3"
      },
      "source": [
        "Train function for **maximizing the zeros** in activation of **QuantizeLayer()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uyCInU7aZMC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_on_quantize(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005,\n",
        "          verbose=1, print_every=100, state=None, schedule={}, checkpoint_path=None):\n",
        "\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "\n",
        "# To store the losses for plotting purpose\n",
        "  losses = []\n",
        "\n",
        "# Set 'L2 norm' as criteria\n",
        "  rate_criterion = nn.MSELoss()\n",
        "\n",
        "# Stochastic Gradient Descend\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "  # Load previous training state (Not Required for this model )\n",
        "  if state:\n",
        "      net.load_state_dict(state['net'])\n",
        "      optimizer.load_state_dict(state['optimizer'])\n",
        "      start_epoch = state['epoch']\n",
        "      losses = state['losses']\n",
        "\n",
        "  # Fast forward lr schedule through already trained epochs\n",
        "  for epoch in range(start_epoch):\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "# TRAINING START\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    sum_loss = 0.0\n",
        "\n",
        "    # Update learning rate when scheduled\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad() #1\n",
        "\n",
        "        outputs = net.layer2[1](net.layer1(net.maxpool(net.relu(net.bn1(net.conv1(inputs))))))\n",
        "\n",
        "        # RATE LOSS\n",
        "        # Approach: Compute the L2-Norm with zero tensor(our target in this case)\n",
        "        # Backpropogation will lead to increasing the no of zeros in activation of QuantizeLayer()\n",
        "        rate_loss = rate_criterion(outputs, torch.zeros_like(outputs))\n",
        "\n",
        "        rate_loss.backward()\n",
        "\n",
        "        if( device == 'cuda:0' or device == 'cpu'):\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            xm.optimizer_step(optimizer= optimizer) # takes a step in gradient direction\n",
        "\n",
        "\n",
        "        losses.append(rate_loss.item())\n",
        "        sum_loss += rate_loss.item()\n",
        "\n",
        "        if i % print_every == print_every-1:    # print every 10 mini-batches\n",
        "            if verbose:\n",
        "              print('[%d, %5d] loss: %.5f' % (epoch, i + 1, sum_loss / print_every))\n",
        "            sum_loss = 0.0\n",
        "\n",
        "    print(\"EPOCH \", epoch)\n",
        "    print(\" Training Accuracy is: \" , accuracy(net ,  dataloader) , end= \"|\")\n",
        "    c,t = no_of_zeros( net , dataloader)\n",
        "    print(\" Zeros: \",c , \" total: \", t , \" Ratio: \",  c/t  )\n",
        "    print( \"Testing Accuracy is: \", accuracy(net , big_cifar_data['test']), end = \"\\n\\n\")\n",
        "\n",
        "    if checkpoint_path: #(Not required for this case)\n",
        "      state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
        "      torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
        "\n",
        "  return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98QJ5wO-fEwJ"
      },
      "source": [
        "Train function for **classification task** for training after QuantizeLayer()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juwE6eqaelrS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_after_quantize(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005,\n",
        "          verbose=1, print_every=100, state=None, schedule={}, checkpoint_path=None):\n",
        "\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "\n",
        "# To store the losses for plotting purpose\n",
        "  losses = []\n",
        "\n",
        "# Set 'L2 norm' as criteria\n",
        "  task_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic Gradient Descend\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "  # Load previous training state (Not Required for this model )\n",
        "  if state:\n",
        "      net.load_state_dict(state['net'])\n",
        "      optimizer.load_state_dict(state['optimizer'])\n",
        "      start_epoch = state['epoch']\n",
        "      losses = state['losses']\n",
        "\n",
        "  # Fast forward lr schedule through already trained epochs\n",
        "  for epoch in range(start_epoch):\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "# TRAINING START\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    sum_loss = 0.0\n",
        "\n",
        "    # Update learning rate when scheduled\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad() #1\n",
        "\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # TASK LOSS\n",
        "        # Approach: Classification using categorical cross entropy.\n",
        "        task_loss = task_criterion(outputs, labels)\n",
        "\n",
        "        task_loss.backward()\n",
        "\n",
        "        # if( device == 'cuda:0' or device == 'cpu'):\n",
        "        optimizer.step()\n",
        "        # else:\n",
        "        #     xm.optimizer_step(optimizer= optimizer) # takes a step in gradient direction\n",
        "\n",
        "\n",
        "        losses.append(task_loss.item())\n",
        "        sum_loss += task_loss.item()\n",
        "\n",
        "        if i % print_every == print_every-1:    # print every 10 mini-batches\n",
        "            if verbose:\n",
        "              print('[%d, %5d] loss: %.5f' % (epoch, i + 1, sum_loss / print_every))\n",
        "            sum_loss = 0.0\n",
        "\n",
        "    print(\"EPOCH \", epoch)\n",
        "    print(\" Training Accuracy is: \" , accuracy(net ,  dataloader) , end= \"|\")\n",
        "    # c,t = no_of_zeros( net , dataloader)\n",
        "    # print(\" Zeros: \",c , \" total: \", t , \" Ratio: \",  c/t  )\n",
        "    print( \"Testing Accuracy is: \", accuracy(net , big_cifar_data['test']), end = \"\\n\\n\")\n",
        "\n",
        "    if checkpoint_path: #(Not required for this case)\n",
        "      state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
        "      torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
        "\n",
        "  return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uHxBDpZgL7r"
      },
      "source": [
        "Train Function for combined rate loss and task loss\n",
        "\n",
        "**loss = Lt + (lambda)*Lr**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMT01LVAua1h"
      },
      "outputs": [],
      "source": [
        "def train_regularized(net, dataloader, epochs=1, lmbda= 0.1 , start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005,\n",
        "          verbose=1, print_every=100, state=None, schedule={}, checkpoint_path=None):\n",
        "\n",
        "#   send the network to device and set it to training mode\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "\n",
        "# Lt (Task Loss) -> CrossEntropyLoss and Lr (Rate Loss) -> Mean Squared Error Loss\n",
        "  losses = []\n",
        "  task_criterion = nn.CrossEntropyLoss()\n",
        "  rate_criterion = nn.MSELoss()\n",
        "\n",
        "# Stochastic Gradient Descend\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "# Load previous training state\n",
        "  if state:\n",
        "      net.load_state_dict(state['net'])\n",
        "      optimizer.load_state_dict(state['optimizer'])\n",
        "      start_epoch = state['epoch']\n",
        "      losses = state['losses']\n",
        "\n",
        "# Fast forward lr schedule through already trained epochs\n",
        "  for epoch in range(start_epoch):\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "\n",
        "    print(\"EPOCH \", epoch)\n",
        "    sum_loss = 0.0\n",
        "    sum_rate = 0.0\n",
        "    sum_task = 0.0\n",
        "\n",
        "    # Update learning rate when scheduled\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "    # BATCH TRAINING\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad() # 1\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        temp = net.layer2[1](net.layer1(net.maxpool(net.relu(net.bn1(net.conv1(inputs))))))\n",
        "\n",
        "        task_loss = task_criterion(outputs, labels)\n",
        "        rate_loss = rate_criterion(temp , torch.zeros_like(temp))\n",
        "\n",
        "        loss_total = task_loss + (lmbda)*rate_loss # loss = Lt + (lambda)*Lr\n",
        "\n",
        "        loss_total.backward()  # autograd magic, computes all the partial derivatives\n",
        "\n",
        "        # if( device == 'cuda:0' or device == 'cpu'):\n",
        "        optimizer.step()\n",
        "        # else:\n",
        "        #     xm.optimizer_step(optimizer= optimizer) # takes a step in gradient direction\n",
        "\n",
        "        losses.append(loss_total.item())\n",
        "        sum_loss += loss_total.item()\n",
        "        sum_task += task_loss.item()\n",
        "        sum_rate += rate_loss.item()\n",
        "\n",
        "        if i % print_every == print_every-1:    # print every 10 mini-batches\n",
        "            if verbose:\n",
        "              print('[%d, %5d] loss: %.5f' % (epoch, i + 1, sum_loss / print_every))\n",
        "            #   print( \"Lr = \" , round(sum_rate/print_every ,4  ), \" Lt = \" , round( sum_task/ print_every , 4 ) )\n",
        "            sum_loss = 0.0\n",
        "            sum_rate = 0.0\n",
        "            sum_task = 0.0\n",
        "\n",
        "    print(\" Training Accuracy is: \" , accuracy(net ,  dataloader) , end= \"|\")\n",
        "    c,t = no_of_zeros( net , dataloader)\n",
        "    print(\" Zeros: \",c , \" total: \", t , \" Ratio: \",  c/t  )\n",
        "    print( \"Testing Accuracy is: \", accuracy(net , big_cifar_data['test']), end = \"\\n\\n\")\n",
        "\n",
        "    if checkpoint_path:\n",
        "      state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
        "      torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
        "\n",
        "  return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLFBwUkg4TP"
      },
      "source": [
        "Helper functions for:\n",
        "\n",
        "1.   Accuracy\n",
        "2.   Plotting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwD5wRlmg2cY"
      },
      "outputs": [],
      "source": [
        "def accuracy(net, dataloader):\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for batch in dataloader:\n",
        "          images, labels = batch[0].to(device), batch[1].to(device)\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return correct/total\n",
        "\n",
        "def no_of_zeros(net, dataloader):\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for batch in dataloader:\n",
        "          images, labels = batch[0].to(device), batch[1].to(device)\n",
        "          outputs = net.layer2[1].quant(net.layer2[1].encoder(net.layer1(net.maxpool(net.relu(net.bn1(net.conv1(inputs)))))))\n",
        "          total += torch.numel(outputs)\n",
        "          correct +=  (torch.numel(outputs) - torch.count_nonzero(outputs).item())\n",
        "  return correct, total\n",
        "\n",
        "def no_of_zeros_new(net, dataloader):\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for batch in dataloader:\n",
        "          images, labels = batch[0].to(device), batch[1].to(device)\n",
        "          outputs = net.layer2[1].quant(net.layer2[1].encoder(net.layer1(net.maxpool(net.relu(net.bn1(net.conv1(images)))))))\n",
        "          total += torch.numel(outputs)\n",
        "          correct +=  (torch.numel(outputs) - torch.count_nonzero(outputs).item())\n",
        "  return correct, total\n",
        "\n",
        "def smooth(x, size):\n",
        "  return np.convolve(x, np.ones(size)/size, mode='valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGGbwym6Y9uW"
      },
      "source": [
        "set device to **cuda:0** if training on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1ykZslhtrBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae45bb7-2720-42d3-ddb6-de941756a2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiTFuLVtZz-P"
      },
      "source": [
        "if using **tpu** use minor modification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLBPbYKjZkX1"
      },
      "outputs": [],
      "source": [
        "# device = xm.xla_device()  # Use TPU\n",
        "# # Use xm.optimizer_step(optimizer= ) for optimizer updates instead of optimizer.step().\n",
        "# print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klQB_PQjZev8"
      },
      "source": [
        "# **1. Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ95PxAzuCF7",
        "outputId": "264327e6-d548-4051-fc89-95f5914401c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "big_cifar_data = get_big_cifar10_data(augmentation=1 , root_dir= './drive/MyDrive/data' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwEXjfiPiUWt"
      },
      "source": [
        "# **2. Load Pretrained Resnet18 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNN483nijR8O"
      },
      "source": [
        "Split Point between Layer1 and Layer2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxKF1VZSuLra",
        "outputId": "3f5a33a5-33fb-45be-b7f4-14453c35aab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.resnet18( pretrained = True )\n",
        "\n",
        "# Set the output to 10 ( ten-classes classification)\n",
        "model.fc = nn.Linear(512 , 10 )\n",
        "\n",
        "# create instance of layer1 and layer2\n",
        "layer1 = model.layer1\n",
        "layer2 = model.layer2\n",
        "\n",
        "# Quantizing Parameter is 1.\n",
        "quant_layer = QuantizeLayer(qp=1)\n",
        "\n",
        "# Created a split-point between the laye1 and layer2\n",
        "model.layer2 = nn.Sequential(layer1 , quant_layer , layer2 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYz1eZEvkBiy"
      },
      "source": [
        "# **3. Train before Quantize Layer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joe5oxkDkAha",
        "outputId": "80df204d-b7f4-40fd-c66a-480f8e98094b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0,   100] loss: 0.50178\n",
            "[0,   200] loss: 0.50145\n",
            "[0,   300] loss: 0.50180\n",
            "EPOCH  0\n",
            " Training Accuracy is:  0.10028| Zeros:  1992813818  total:  3276800000  Ratio:  0.6081585137939454\n",
            "Testing Accuracy is:  0.1006\n",
            "\n",
            "[1,   100] loss: 0.50098\n",
            "[1,   200] loss: 0.50115\n",
            "[1,   300] loss: 0.50047\n",
            "EPOCH  1\n",
            " Training Accuracy is:  0.10058| Zeros:  1992832109  total:  3276800000  Ratio:  0.6081640957641602\n",
            "Testing Accuracy is:  0.1006\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss1 = train_on_quantize( model , big_cifar_data['train'] , epochs=2 , lr=0.001 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eBr0_ItDQfZ",
        "outputId": "ab6acb95-eb0f-442e-d392-d9fa055c12e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0,   100] loss: 0.50190\n",
            "[0,   200] loss: 0.50140\n",
            "[0,   300] loss: 0.50171\n",
            "EPOCH  0\n",
            " Training Accuracy is:  0.10052| Zeros:  1991736739  total:  3276800000  Ratio:  0.6078298153686523\n",
            "Testing Accuracy is:  0.1005\n",
            "\n",
            "[1,   100] loss: 0.50140\n",
            "[1,   200] loss: 0.50106\n",
            "[1,   300] loss: 0.50108\n",
            "EPOCH  1\n",
            " Training Accuracy is:  0.10082| Zeros:  1991722988  total:  3276800000  Ratio:  0.6078256188964843\n",
            "Testing Accuracy is:  0.1005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss1_contd = train_on_quantize( model , big_cifar_data['train'] , epochs = 2, lr =0.01 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-po3q5qQbso",
        "outputId": "65349218-9620-4623-e9b4-65ec24e49f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1992841842   3276800000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6081670660400391"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c,t = no_of_zeros( model , big_cifar_data['train'])\n",
        "print( c ,' ',  t )\n",
        "c/t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehzHa41tlCwj"
      },
      "source": [
        "# **4. Freeze all layers before Quantize Layer.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "724DhG-9UHjh"
      },
      "source": [
        "Layers include\n",
        "\n",
        "*   conv1\n",
        "*   bn1\n",
        "*   layer1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZC9UowalqI3"
      },
      "outputs": [],
      "source": [
        "for p in model.conv1.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for p in model.bn1.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for p in model.layer1.parameters():\n",
        "    p.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z0eJdoNkcoi"
      },
      "source": [
        "# **5. Train after Quantize Layers.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlVsiRUeUb9x"
      },
      "outputs": [],
      "source": [
        "loss2 = train_after_quantize(model , big_cifar_data['train'] , epochs= 5 , lr = 0.01 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtDLCxs6uR3r",
        "outputId": "3321211c-763c-4ce1-fa7c-e563d812c72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Testing accuracy is : 0.728900 \n"
          ]
        }
      ],
      "source": [
        "print(\" Testing accuracy is : %f \" %accuracy(model , big_cifar_data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMDHVms801GG",
        "outputId": "da424807-dc2c-4e97-cd1f-4fc7ca526353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training accuracy is : 0.749940 \n"
          ]
        }
      ],
      "source": [
        "print(\" Training accuracy is : %f \" %accuracy(model , big_cifar_data['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVhL_J7GXVzG"
      },
      "source": [
        "# **6. Plotting graph for loss over the epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwa1SU26S_Dk"
      },
      "outputs": [],
      "source": [
        "plt.plot(smooth(loss1 , 50 ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtddVqTOXqKS"
      },
      "outputs": [],
      "source": [
        "plt.plot(smooth(loss2 , 50 ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82QuQmI-hjKI"
      },
      "source": [
        "# **7. Train Combined. using Lr and Lt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SDf1R0Tln0"
      },
      "source": [
        "    next training for epochs = 4 at lr = 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkc6nvRVhtEU"
      },
      "outputs": [],
      "source": [
        "model_comb = torchvision.models.resnet18( pretrained = True )\n",
        "\n",
        "# Set the output to 10 ( ten-classes classification)\n",
        "model_comb.fc = nn.Linear(512 , 10 )\n",
        "\n",
        "# create instance of layer1 and layer2\n",
        "layer1 = model_comb.layer1\n",
        "layer2 = model_comb.layer2\n",
        "\n",
        "# Quantizing Parameter is 2.\n",
        "quant_layer = QuantizeLayer(qp=1)\n",
        "\n",
        "# Created a split-point between the laye1 and layer2\n",
        "model_comb.layer2 = nn.Sequential(layer1 , quant_layer , layer2 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaHIP7rFxURq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295f77d1-6428-4556-8f65-f29d309b5828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH  0\n",
            "[0,   100] loss: 0.78821\n",
            "[0,   200] loss: 0.39343\n",
            "[0,   300] loss: 0.35372\n",
            " Training Accuracy is:  0.90124| Zeros:  2247549069  total:  3276800000  Ratio:  0.6858975430297851\n",
            "Testing Accuracy is:  0.8827\n",
            "\n",
            "EPOCH  1\n",
            "[1,   100] loss: 0.59317\n",
            "[1,   200] loss: 0.43584\n",
            "[1,   300] loss: 0.37420\n",
            " Training Accuracy is:  0.90638| Zeros:  2623206186  total:  3276800000  Ratio:  0.8005389971923829\n",
            "Testing Accuracy is:  0.8921\n",
            "\n",
            "EPOCH  2\n",
            "[2,   100] loss: 0.29237\n",
            "[2,   200] loss: 0.30556\n",
            "[2,   300] loss: 0.27987\n",
            " Training Accuracy is:  0.90462| Zeros:  2659822750  total:  3276800000  Ratio:  0.8117134857177735\n",
            "Testing Accuracy is:  0.8822\n",
            "\n",
            "EPOCH  3\n",
            "[3,   100] loss: 0.25106\n",
            "[3,   200] loss: 0.24504\n",
            "[3,   300] loss: 0.23476\n",
            " Training Accuracy is:  0.94694| Zeros:  2729132483  total:  3276800000  Ratio:  0.8328651376342774\n",
            "Testing Accuracy is:  0.9266\n",
            "\n",
            "EPOCH  4\n",
            "[4,   100] loss: 0.22435\n",
            "[4,   200] loss: 0.21259\n",
            "[4,   300] loss: 0.20726\n",
            " Training Accuracy is:  0.9474| Zeros:  2775734818  total:  3276800000  Ratio:  0.8470870416259766\n",
            "Testing Accuracy is:  0.919\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lss = train_regularized( model_comb , big_cifar_data['train'] , epochs = 5 , lr = 0.01 , print_every =100  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_comb , './drive/MyDrive/model.pth')"
      ],
      "metadata": {
        "id": "hy1UTsT2k_Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lss = train_regularized( model_comb , big_cifar_data['train'] , epochs = 3 , lmbda=0.1 , print_every =100 )"
      ],
      "metadata": {
        "id": "b3ONDU77-Doy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ1jhZEHzqyC",
        "outputId": "085d4bc4-61df-4264-b734-d54618b3dcd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8462426834106446\n"
          ]
        }
      ],
      "source": [
        "c ,t = no_of_zeros(model_comb , big_cifar_data['test'])\n",
        "# print(c)\n",
        "print(c/t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNk0Mt7yik9U"
      },
      "outputs": [],
      "source": [
        "print(\"training accuracy : \", accuracy( model_comb , big_cifar_data['train']))\n",
        "print(\"testing accuracy : \", accuracy( model_comb , big_cifar_data['test']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_comb)"
      ],
      "metadata": {
        "id": "qvnlw4iNzmkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "tjND1qJ2i4Ch",
        "outputId": "f50285ac-2ddd-4396-cb68-1c72b3971e4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faf952cf730>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(smooth(lss , 50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAQRG4j6qGOS"
      },
      "source": [
        "#**Huffmann Coding**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the frequency table for huffmann encoding in *data_dic*."
      ],
      "metadata": {
        "id": "6svoWncks0Pu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEGAZ7i9XJUr"
      },
      "outputs": [],
      "source": [
        "def huffmann_data_train(net, dataloader):\n",
        "    dic = {} # an empty dictioinary for huffmann coding\n",
        "    net.to(device)\n",
        "\n",
        "    for batch in dataloader:\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "        outputs = net.layer2[1](net.layer1(net.maxpool(net.relu(net.bn1(net.conv1(images))))))\n",
        "        l = outputs.flatten().tolist()\n",
        "        for i in l:\n",
        "            if( dic.get(i) is None):\n",
        "                dic[i] = 1\n",
        "            else:\n",
        "                dic[i]+=1\n",
        "\n",
        "    return dic\n",
        "\n",
        "# build data_dict on 'train' data\n",
        "data_dict = huffmann_data_train(model_comb , big_cifar_data['train'])\n",
        "\n",
        "# data_dict = {\"0.0\": 2775722279, \"1.0\": 472760502, \"2.0\": 25501475, \"3.0\": 2514363, \"4.0\": 252588, \"5.0\": 40634, \"6.0\": 6465, \"7.0\": 1242, \"8.0\": 264, \"9.0\": 90, \"10.0\": 71, \"11.0\": 18, \"12.0\": 9, \"13.0\": 8, \"14.0\": 7, \"15.0\": 6}\n",
        "\n",
        "with open(\"./drive/MyDrive/dictionary.txt\", \"w\") as outfile:\n",
        "    json.dump(data_dict , outfile )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('./drive/MyDrive/dictionary.txt' , 'r') as f :\n",
        "    data_dic = json.load(f)\n",
        "\n",
        "model = torch.load('./drive/MyDrive/model.pth') # a model with 94% accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9zjb08noTQE",
        "outputId": "f3849d55-bbcb-45cf-aee0-53baf9b81e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0.0': 2775722279, '1.0': 472760502, '2.0': 25501475, '3.0': 2514363, '4.0': 252588, '5.0': 40634, '6.0': 6465, '7.0': 1242, '8.0': 264, '9.0': 90, '10.0': 71, '11.0': 18, '12.0': 9, '13.0': 8, '14.0': 7, '15.0': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BPP Computation**"
      ],
      "metadata": {
        "id": "QInA7jytuWmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define hoff module at \"./drive/MyDrive/huffmann_encoding\"\n",
        "import hoff as he\n",
        "\n",
        "c1, c2 = 0, 0\n",
        "bpp = 0\n",
        "for batch in big_cifar_data['train']:\n",
        "\n",
        "    images, labels = batch[0].to(device), batch[1].to(device)\n",
        "    outputs = model.layer2[1](model.layer1(model.maxpool(model.relu(model.bn1(model.conv1(images))))))\n",
        "    the_data = outputs.flatten().tolist()\n",
        "    encoding, treehead , c1 , c2  = he.HuffmanEncoding( the_data, train_dic = data_dic)\n",
        "\n",
        "    break\n",
        "\n",
        "bpp = c2/(128*3*128*128)\n",
        "print( \"Earlier required bpp was : \" , 8 )\n",
        "print(\"BPP is  \" , bpp)"
      ],
      "metadata": {
        "id": "xTomJU5lsIg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5a3f6-60f7-4903-8a02-33cff784022b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Space usage before compression (in bits): 67108864\n",
            "Space usage after compression (in bits): 9719988\n",
            "Earlier required bpp was :  8\n",
            "BPP is   1.5449504852294922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test with VAE layer for encoding.**"
      ],
      "metadata": {
        "id": "n-hgzmGMviXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        self.shape = args\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, stride=2, kernel_size=3, bias=False, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.Conv2d(32, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.z_mean = torch.nn.Linear(2048*2, 200)\n",
        "        self.z_log_var = torch.nn.Linear(2048*2, 200)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "                torch.nn.Linear(200, 2048*2),\n",
        "                Reshape(-1, 64, 8, 8),\n",
        "                #\n",
        "                nn.UpsamplingNearest2d(scale_factor=2),\n",
        "                nn.Conv2d(64, 64, stride=1, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.UpsamplingNearest2d(scale_factor=2),\n",
        "                nn.Conv2d(64, 64, stride=1, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.UpsamplingNearest2d(scale_factor=2),\n",
        "                nn.Conv2d(64, 32, stride=1, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                nn.Dropout2d(0.25),\n",
        "                #\n",
        "                nn.UpsamplingNearest2d(scale_factor=2),\n",
        "                nn.Conv2d(32, 3, stride=1, kernel_size=3, padding=1),\n",
        "                nn.Sigmoid()\n",
        "                )\n",
        "\n",
        "\n",
        "    def encoding_fn(self, x):\n",
        "        x = self.encoder(x)\n",
        "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
        "        encoded = self.reparameterize(z_mean, z_log_var)\n",
        "        return encoded\n",
        "\n",
        "\n",
        "    def reparameterize(self, z_mu, z_log_var):\n",
        "        eps = torch.randn(z_mu.size(0), z_mu.size(1)).to(z_mu.get_device())\n",
        "        z = z_mu + eps * torch.exp(z_log_var/2.)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
        "        encoded = self.reparameterize(z_mean, z_log_var)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, z_mean, z_log_var, decoded"
      ],
      "metadata": {
        "id": "ppavtEBT_oDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE()\n",
        "vae.load_state_dict(torch.load('./drive/MyDrive/vae_on_cifar_data.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIL12Ehuj6kJ",
        "outputId": "863b6e9e-2a05-41d8-e757-f647dd133d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers with its parameters\n",
        "for p in vae.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "vUM6EhrFQ-8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cifar = torch.load('./drive/MyDrive/model_forkd.pth')"
      ],
      "metadata": {
        "id": "rB8S8kfKRSco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Acuracy of model \" , accuracy(model_cifar , big_cifar_data['train']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLFua5pJQ-zB",
        "outputId": "1f2c31f0-ca3b-411e-f251-3f46bc583dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuracy of model  0.96602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class optimized_model(nn.Module):\n",
        "\n",
        "    def __init__(self) :\n",
        "        super().__init__()\n",
        "\n",
        "        self.vae_layer = vae\n",
        "        self.model_cifar = model_cifar\n",
        "\n",
        "    def forward(self , x ):\n",
        "\n",
        "        # encoded, z_mean, z_log_var, decoded_images = self.vae_layer(x)\n",
        "        return model_cifar(self.vae_layer(x)[3])\n",
        "\n"
      ],
      "metadata": {
        "id": "1BGWGqQXSNaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nu = optimized_model()\n"
      ],
      "metadata": {
        "id": "h5x0IOwxTPrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Accuracy :\" , accuracy(nu , big_cifar_data['train']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afgpjNiMTgGS",
        "outputId": "e7e4861c-eaa4-4208-b60d-a1f23065b0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.24912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( vae(          torch.rand( [1 , 3, 128 , 128 ]).cuda()    )[1])"
      ],
      "metadata": {
        "id": "rMaBS3lpUA6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in nu.parameters():\n",
        "    print(p.requires_grad)"
      ],
      "metadata": {
        "id": "pUnGqiGwVbXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lssos = train_after_quantize( nu , big_cifar_data['train'] , epochs = 7 , lr = 0.001 , print_every = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-8YvGUoVyPD",
        "outputId": "05aec6c3-d3cd-498c-b20d-f4bde468b70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0,   100] loss: 0.85671\n",
            "[0,   200] loss: 0.81056\n",
            "[0,   300] loss: 0.75649\n",
            "EPOCH  0\n",
            " Training Accuracy is:  0.75866|Testing Accuracy is:  0.7379\n",
            "\n",
            "[1,   100] loss: 0.69410\n",
            "[1,   200] loss: 0.68126\n",
            "[1,   300] loss: 0.69036\n",
            "EPOCH  1\n",
            " Training Accuracy is:  0.7579|Testing Accuracy is:  0.7357\n",
            "\n",
            "[2,   100] loss: 0.67559\n",
            "[2,   200] loss: 0.66036\n",
            "[2,   300] loss: 0.67250\n",
            "EPOCH  2\n",
            " Training Accuracy is:  0.76766|Testing Accuracy is:  0.744\n",
            "\n",
            "[3,   100] loss: 0.65037\n",
            "[3,   200] loss: 0.63983\n",
            "[3,   300] loss: 0.65242\n",
            "EPOCH  3\n",
            " Training Accuracy is:  0.7704|Testing Accuracy is:  0.7389\n",
            "\n",
            "[4,   100] loss: 0.62942\n",
            "[4,   200] loss: 0.64449\n",
            "[4,   300] loss: 0.64367\n",
            "EPOCH  4\n",
            " Training Accuracy is:  0.77748|Testing Accuracy is:  0.7483\n",
            "\n",
            "[5,   100] loss: 0.62115\n",
            "[5,   200] loss: 0.64060\n",
            "[5,   300] loss: 0.63241\n",
            "EPOCH  5\n",
            " Training Accuracy is:  0.77912|Testing Accuracy is:  0.7488\n",
            "\n",
            "[6,   100] loss: 0.60975\n",
            "[6,   200] loss: 0.61718\n",
            "[6,   300] loss: 0.64265\n",
            "EPOCH  6\n",
            " Training Accuracy is:  0.77772|Testing Accuracy is:  0.7444\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lssos = train_after_quantize( nu , big_cifar_data['train'] , epochs = 7 , lr = 0.0001 , print_every = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD0nVi38ekiH",
        "outputId": "60e40c72-5889-42fe-826d-f46e4d787d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0,   100] loss: 0.72051\n",
            "[0,   200] loss: 0.70064\n",
            "[0,   300] loss: 0.70593\n",
            "EPOCH  0\n",
            " Training Accuracy is:  0.7772|Testing Accuracy is:  0.7459\n",
            "\n",
            "[1,   100] loss: 0.62751\n",
            "[1,   200] loss: 0.62604\n",
            "[1,   300] loss: 0.61255\n",
            "EPOCH  1\n",
            " Training Accuracy is:  0.78408|Testing Accuracy is:  0.7512\n",
            "\n",
            "[2,   100] loss: 0.59095\n",
            "[2,   200] loss: 0.62167\n",
            "[2,   300] loss: 0.60542\n",
            "EPOCH  2\n",
            " Training Accuracy is:  0.78678|Testing Accuracy is:  0.7531\n",
            "\n",
            "[3,   100] loss: 0.60462\n",
            "[3,   200] loss: 0.59970\n",
            "[3,   300] loss: 0.61081\n",
            "EPOCH  3\n",
            " Training Accuracy is:  0.78578|Testing Accuracy is:  0.754\n",
            "\n",
            "[4,   100] loss: 0.59859\n",
            "[4,   200] loss: 0.59071\n",
            "[4,   300] loss: 0.61003\n",
            "EPOCH  4\n",
            " Training Accuracy is:  0.7879|Testing Accuracy is:  0.7542\n",
            "\n",
            "[5,   100] loss: 0.60048\n",
            "[5,   200] loss: 0.59381\n",
            "[5,   300] loss: 0.60128\n",
            "EPOCH  5\n",
            " Training Accuracy is:  0.78674|Testing Accuracy is:  0.7527\n",
            "\n",
            "[6,   100] loss: 0.59026\n",
            "[6,   200] loss: 0.60231\n",
            "[6,   300] loss: 0.59571\n",
            "EPOCH  6\n",
            " Training Accuracy is:  0.78808|Testing Accuracy is:  0.7512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flssos = train_after_quantize( nu , big_cifar_data['train'] , epochs = 7 , lr = 0.0001 , print_every = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ecsGGBndhMql",
        "outputId": "dd111501-2a92-4479-81c1-53951b0f0825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_after_quantize' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-38775d74d022>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflssos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_after_quantize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnu\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbig_cifar_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_after_quantize' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}